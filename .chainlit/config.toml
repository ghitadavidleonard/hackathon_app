[project]
# Whether to enable telemetry (default: true). No personal data is collected.
enable_telemetry = true


# List of environment variables to be provided by each user to use the app.
user_env = []

# Duration (in seconds) during which the session is saved when the connection is lost
session_timeout = 3600

# Duration (in seconds) of the user session expiry
user_session_timeout = 1296000  # 15 days

# Enable third parties caching (e.g., LangChain cache)
cache = false

# Authorized origins
allow_origins = ["*"]

[features]
# Process and display HTML in messages. This can be a security risk (see https://stackoverflow.com/questions/19603097/why-is-it-dangerous-to-render-user-generated-html-or-javascript)
unsafe_allow_html = false

# Process and display mathematical expressions. This can clash with "$" characters in messages.
latex = false

# Autoscroll new user messages at the top of the window
user_message_autoscroll = true

# Automatically tag threads with the current chat profile (if a chat profile is used)
auto_tag_thread = true

# Allow users to edit their own messages
edit_message = true

# Authorize users to spontaneously upload files with messages
[features.spontaneous_file_upload]
    enabled = true
    # Define accepted file types using MIME types
    # Examples:
    # 1. For specific file types:
    #    accept = ["image/jpeg", "image/png", "application/pdf"]
    # 2. For all files of certain type:
    #    accept = ["image/*", "audio/*", "video/*"]
    # 3. For specific file extensions:
    #    accept = { "application/octet-stream" = [".xyz", ".pdb"] }
    # Note: Using "*/*" is not recommended as it may cause browser warnings
    accept = ["*/*"]
    max_files = 20
    max_size_mb = 500

[features.audio]
    # Sample rate of the audio
    sample_rate = 24000

[features.speech_to_text]
    # Enable voice input
    enabled = true
    # Use Whisper model for transcription - whisper-1 is the OpenAI API version with better noise handling
    whisper_model = "whisper-1"
    
    # Voice activity detection settings - optimized for background noise reduction
    [features.speech_to_text.vad]
    # The threshold above which the VAD will consider the audio as speech
    # Higher values (0.4-0.6) require louder speech but better filter out background noise
    threshold = 0.5
    # The amount of silence in milliseconds that needs to pass before considering the speech as complete
    # Shorter values stop recording earlier when noise is detected
    auto_stop = 1000
    # The maximum time in milliseconds to record audio (regardless of speech detection)
    max_record_time = 15000
    # Noise suppression level (0 to 1, where 1 is maximum suppression)
    noise_suppression = 0.9
    
    # Advanced settings
    [features.speech_to_text.advanced]
    # Enhanced noise reduction (works with standard Whisper)
    enhanced_noise_reduction = true
    # Focus on human voice frequencies (300-3000 Hz)
    voice_focus = true
    # Apply amplitude filtering for background noise
    amplitude_filtering = true
    # Threshold for amplitude filtering (lower values = more filtering)
    amplitude_threshold = 500
    # Dynamically adjust noise threshold based on environment
    dynamic_threshold = true
    # Apply strict VAD filtering that requires clearer speech
    strict_vad_filtering = true
    # Suppress ambient noise (fans, AC units, computer fans)
    ambient_noise_suppression = true
    # Normalize audio to improve recognition in noisy environments
    normalize_audio = true
    # Maximum amplitude filtering - ignores sounds below threshold
    max_amplitude_filtering = true
    
    # Realtime OpenAI speech configuration
    [features.speech_to_text.realtime]
    # Enable realtime OpenAI speech capabilities
    enabled = true

[features.text_to_speech]
    # Enable text-to-speech functionality
    enabled = true
    # Use OpenAI's TTS model for high-quality voice synthesis
    tts_model = "tts-1"
    # Voice to use for speech synthesis (alloy, echo, fable, onyx, nova, shimmer)
    voice = "alloy"
    # Speed of speech (0.25 to 4.0, where 1.0 is normal speed)
    speed = 1.0
    # Auto-play audio responses when they're generated
    auto_play = true
    # Sample rate for audio output
    sample_rate = 24000

[features.mcp.sse]
    enabled = true

[features.mcp.stdio]
    enabled = true
    # Only the executables in the allow list can be used for MCP stdio server.
    # Only need the base name of the executable, e.g. "npx", not "/usr/bin/npx".
    # Please don't comment this line for now, we need it to parse the executable name.
    allowed_executables = [ "npx", "uvx" ]

[UI]
# Name of the assistant.
name = "Assistant"

# default_theme = "dark"

# layout = "wide"

# default_sidebar_state = "open"

# Description of the assistant. This is used for HTML tags.
# description = ""

# Chain of Thought (CoT) display mode. Can be "hidden", "tool_call" or "full".
cot = "full"

# Specify a CSS file that can be used to customize the user interface.
# The CSS file can be served from the public directory or via an external link.
# custom_css = "/public/test.css"

# Specify additional attributes for a custom CSS file
# custom_css_attributes = "media=\"print\""

# Specify a JavaScript file that can be used to customize the user interface.
# The JavaScript file can be served from the public directory.
# custom_js = "/public/test.js"

# Specify additional attributes for custom JS file
# custom_js_attributes = "async type = \"module\""

# Custom login page image, relative to public directory or external URL
# login_page_image = "/public/custom-background.jpg"

# Custom login page image filter (Tailwind internal filters, no dark/light variants)
# login_page_image_filter = "brightness-50 grayscale"
# login_page_image_dark_filter = "contrast-200 blur-sm"

# Specify a custom meta image url.
# custom_meta_image_url = "https://chainlit-cloud.s3.eu-west-3.amazonaws.com/logo/chainlit_banner.png"

# Specify a custom build directory for the frontend.
# This can be used to customize the frontend code.
# Be careful: If this is a relative path, it should not start with a slash.
# custom_build = "./public/build"

# Specify optional one or more custom links in the header.
# [[UI.header_links]]
#     name = "Issues"
#     display_name = "Report Issue"
#     icon_url = "https://avatars.githubusercontent.com/u/128686189?s=200&v=4"
#     url = "https://github.com/Chainlit/chainlit/issues"

[meta]
generated_by = "2.5.5"
